# Initialize the Prompt based on sampling from the vocabulary where the
# embeddings are loaded from the initial model checkpoint
# `INITIAL_CHECKPOINT_PATH`.
# Provides PROMPT
#
# Requires PROMPT_LENGTH to be set.
#
# Include as a --gin_file argument after the `models/*.gin` arguments.
from __gin__ import dynamic_registration

from prompt_tuning import prompts
from prompt_tuning.train import prompts as train_prompts

EMBEDDING_FILE = %gin.REQUIRED

PROMPT = @train_prompts.Prompt
train_prompts.Prompt.prompt = @prompts.Prompt()

prompts.Prompt:
  length = %PROMPT_LENGTH
  prompt_init = @prompt_init/prompts.from_sample_of_embeddings()

prompt_init/prompts.from_sample_of_embeddings:
  embeddings = @prompt_init/prompts.t5x_load()
  population_size = 5000

prompt_init/prompts.t5x_load:
  checkpoint_path = %INITIAL_CHECKPOINT_PATH
  variable_path = "token_embedder/embedding"

# Then set overrides in the launch script:
# --gin.EMBEDDING_FILE="'/path/to/numpy/embeddings/t5_1_1_lm_adaptation/xxl.npy'" \
