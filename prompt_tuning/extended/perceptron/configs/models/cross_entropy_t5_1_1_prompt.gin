# T5 1.1 Base Prompt model, trained with a Perceptron Loss.
# Provides MODEL, PROMPT, and PROMPT_LENGTH

from __gin__ import dynamic_registration
from prompt_tuning.extended.perceptron.train import models

include 'prompt_tuning/configs/models/t5_1_1_prompt.gin'

MODEL = @models.CrossEntropyEncoderDecoderModel()
models.CrossEntropyEncoderDecoderModel:
  module = %ARCHITECTURE
  input_vocabulary = %VOCABULARY
  output_vocabulary = %VOCABULARY
  optimizer_def = %OPTIMIZER
  z_loss = %Z_LOSS
  label_smoothing = %LABEL_SMOOTHING
  loss_normalizing_factor = %LOSS_NORMALIZING_FACTOR
  length_normalize = True
